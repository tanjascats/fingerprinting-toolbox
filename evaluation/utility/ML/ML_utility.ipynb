{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3244e9c",
   "metadata": {},
   "source": [
    "# Utility Evaluation\n",
    "This notebook presents the reproducible results for the effects of fingerprintg on the ML performance. \n",
    "We use classification task and a range of different classifiers to evaluate the utility.\n",
    "\n",
    "1. Adult Census dataset\n",
    "    - 1.1. Baseline performance    \n",
    "    - 1.2. Demo utility evaluation process\n",
    "    - 1.3. Full utility evaluation\n",
    "2. German Credit dataset\n",
    "    - 2.1. Baseline performance\n",
    "    - 2.2. Demo utility evaluation process\n",
    "    - 2.3. Full utility evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c349aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, preprocessing, model_selection\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b75055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('C:/Users/tsarcevic/PycharmProjects/fingerprinting-toolbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76e922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Adult, GermanCredit, Dataset\n",
    "from scheme import Universal\n",
    "from utils import fp_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de5c0d",
   "metadata": {},
   "source": [
    "## 1. Adult census dataset\n",
    "### 1.1. Baseline performance\n",
    "Original baseline accuracy on clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161156c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets._dataset.Adult at 0x290040166e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = Adult()\n",
    "# cleaning the data \n",
    "original_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b41af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical features and drop redundant \n",
    "original_data.number_encode_categorical()\n",
    "original_data = original_data.drop(['fnlwgt','education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2845eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target attribute\n",
    "X = original_data.get_features()\n",
    "y = original_data.get_target()\n",
    "\n",
    "# scale features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns) #, index=X.index)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cbc32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [GradientBoostingClassifier(), LinearSVC(), MLPClassifier(), RandomForestClassifier(), LogisticRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbabfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adult = []\n",
    "# columns = ['classifier', 'gamma', 'accuracy_mean', 'accuracy_std', 'f1_mean', 'f1_std'] \n",
    "# gamma -> 0 for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2e603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier()\n",
      "Accuracy: 0.861 (+/- 0.008)\n",
      "F1 score: 0.683 (+/- 0.019)\n",
      "LinearSVC()\n",
      "Accuracy: 0.820 (+/- 0.005)\n",
      "F1 score: 0.538 (+/- 0.018)\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "for clf in classifiers:\n",
    "    scores = model_selection.cross_validate(clf, X, y, scoring = ['accuracy', 'f1'], cv=10)\n",
    "    print(clf)\n",
    "    print(\"\\tAccuracy: %0.3f (+/- %0.3f)\\n\\tF1 score: %0.3f (+/- %0.3f)\" \n",
    "          % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2,\n",
    "            scores['test_f1'].mean(), scores['test_f1'].std() * 2))\n",
    "    \n",
    "    # save scores\n",
    "    results_adult.append([clf, 0, \n",
    "                      scores['test_accuracy'].mean(), scores['test_accuracy'].std(),\n",
    "                      scores['test_f1'].mean(), scores['test_f1'].std()])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfac3f",
   "metadata": {},
   "source": [
    "### 1.2. Demo utility effects evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fingerprinting scheme\n",
    "scheme = Universal(gamma=1, fingerprint_bit_length=64)\n",
    "fp_dataset = scheme.insertion(original_data, secret_key=4370315727, recipient_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check fingerprint detection\n",
    "suspect = scheme.detection(fp_dataset, secret_key=4370315727)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce preprocessing of the original dataset\n",
    "X_fp = fp_dataset.get_features()\n",
    "y_fp = fp_dataset.get_target()\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_fp = pd.DataFrame(scaler.fit_transform(X_fp), columns=X_fp.columns) #, index=X_fp.index)\n",
    "X_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e54a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_scores = fp_cross_val_score(clf, X, y, X_fp, y_fp, cv=10, scoring = ['accuracy', 'f1'])\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\\nF1 score: %0.3f (+/- %0.3f)\" \n",
    "      % (fp_scores['test_accuracy'].mean(), fp_scores['test_accuracy'].std() * 2,\n",
    "        fp_scores['test_f1'].mean(), fp_scores['test_f1'].std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84686a",
   "metadata": {},
   "source": [
    "### 1.3. Full evaluation  \n",
    "\n",
    "1. Define gammas\n",
    "2. Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c11d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [1, 1.5, 2]\n",
    "#classifiers = [GradientBoostingClassifier(), LinearSVC(), MLPClassifier(), RandomForestClassifier(), LogisticRegression()]\n",
    "secret_key = 4370315727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gammas:\n",
    "    # fingerprint\n",
    "    scheme = Universal(gamma=g, fingerprint_bit_length=64)\n",
    "    fp_dataset = scheme.insertion(original_data, secret_key=secret_key, recipient_id=0)\n",
    "    # split\n",
    "    X_fp = fp_dataset.get_features()\n",
    "    y_fp = fp_dataset.get_target()\n",
    "    # scale\n",
    "    X_fp = pd.DataFrame(scaler.fit_transform(X_fp), columns=X_fp.columns) #, index=X_fp.index)\n",
    "    \n",
    "    # score\n",
    "    for clf in classifiers:\n",
    "        print(clf)\n",
    "        fp_scores = fp_cross_val_score(clf, X, y, X_fp, y_fp, cv=10, scoring = ['accuracy', 'f1'])\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f)\\nF1 score: %0.3f (+/- %0.3f)\" \n",
    "              % (fp_scores['test_accuracy'].mean(), fp_scores['test_accuracy'].std() * 2,\n",
    "              fp_scores['test_f1'].mean(), fp_scores['test_f1'].std() * 2))\n",
    "        # save scores\n",
    "        results_adult.append([clf, g, \n",
    "                              fp_scores['test_accuracy'].mean(), fp_scores['test_accuracy'].std(),\n",
    "                              fp_scores['test_f1'].mean(), fp_scores['test_f1'].std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adult = pd.DataFrame(results_adult,\n",
    "                             columns=['classifier', 'gamma', 'accuracy_mean', 'accuracy_std', 'f1_mean', 'f1_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adult.to_csv('ML_utility_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a6640",
   "metadata": {},
   "source": [
    "## 2. German Credit data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3-venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
